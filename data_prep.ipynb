{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytaj i przetwórz mr_linear\n",
    "mr_linear = pl.read_csv('C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\model_df_linear.csv', ignore_errors=True)\n",
    "mr_linear = (\n",
    "    mr_linear\n",
    "    .select(['patient_id', 'recording', 'create_date', 'date', 'visit_date', 'time_point', \n",
    "             'confidence', 'label', 'chunks_count', 'euthymia', 'depression', 'mania', 'mixed'])\n",
    "    .rename({\"recording\": \"mr\", \"confidence\": \"confidence_linear\"})\n",
    "    .with_columns([\n",
    "        pl.when(pl.col(\"mr\") == \"NA\").then(None).otherwise(pl.col(\"mr\")).cast(pl.Int64).alias('mr')\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Wczytaj i przetwórz mr_constant\n",
    "mr_constant = pl.read_csv('C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\model_df_constant.csv', ignore_errors=True)\n",
    "mr_constant = (\n",
    "    mr_constant\n",
    "    .select([ 'recording', 'confidence'])  # Tylko potrzebne kolumny\n",
    "    .rename({\"recording\": \"mr\", \"confidence\": \"confidence_constant\"})\n",
    "    .with_columns([\n",
    "        pl.when(pl.col(\"mr\") == \"NA\").then(None).otherwise(pl.col(\"mr\")).cast(pl.Int64).alias('mr')\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Wczytaj i przetwórz mr_gauss\n",
    "mr_gauss = pl.read_csv('C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\model_df.csv', ignore_errors=True)\n",
    "mr_gauss = (\n",
    "    mr_gauss\n",
    "    .select([ 'recording', 'confidence'])  # Tylko potrzebne kolumny\n",
    "    .rename({\"recording\": \"mr\", \"confidence\": \"confidence_gauss\"})\n",
    "    .with_columns([\n",
    "        pl.when(pl.col(\"mr\") == \"NA\").then(None).otherwise(pl.col(\"mr\")).cast(pl.Int64).alias('mr')\n",
    "    ])\n",
    ")\n",
    "\n",
    "# # Połącz wszystkie ramki danych na podstawie kolumny \"mr\" i wspólnych atrybutów\n",
    "mr = (\n",
    "    mr_linear\n",
    "    .join(mr_constant, on=\"mr\" )#, how=\"left\")\n",
    "    .join(mr_gauss, on=\"mr\" ) #, how=\"left\")\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>label</th><th>suma</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;euthymia&quot;</td><td>1698</td></tr><tr><td>&quot;depression&quot;</td><td>1589</td></tr><tr><td>&quot;mania&quot;</td><td>816</td></tr><tr><td>&quot;mixed&quot;</td><td>434</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 2)\n",
       "┌────────────┬──────┐\n",
       "│ label      ┆ suma │\n",
       "│ ---        ┆ ---  │\n",
       "│ str        ┆ u32  │\n",
       "╞════════════╪══════╡\n",
       "│ euthymia   ┆ 1698 │\n",
       "│ depression ┆ 1589 │\n",
       "│ mania      ┆ 816  │\n",
       "│ mixed      ┆ 434  │\n",
       "└────────────┴──────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ramka = mr.group_by(['patient_id','visit_date','label']).agg(pl.col(\"label\").count().alias(\"count\")).sort('patient_id').filter(pl.col('visit_date')!='NA')\n",
    "ramka.group_by('label').agg(pl.col('count').sum().alias('suma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podział na 5 grup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dane_1472 \u001b[38;5;241m=\u001b[39m  \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdanonki\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mvol2\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m1472_all.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#12sek\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# dane_2004 =  pl.read_csv('C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\2004_data.csv' , n_rows = 5000000 , ignore_errors=True ) #11sek\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# dane_2004 = dane_2004.drop(dane_2004.columns[0]) #jeśli jest 100 kolumn\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# dane1 = [dane_1472, dane_2004, dane_6139, dane_8281]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\phd\\lib\\site-packages\\polars\\_utils\\deprecation.py:92\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m     89\u001b[0m     _rename_keyword_argument(\n\u001b[0;32m     90\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[0;32m     91\u001b[0m     )\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\phd\\lib\\site-packages\\polars\\_utils\\deprecation.py:92\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m     89\u001b[0m     _rename_keyword_argument(\n\u001b[0;32m     90\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[0;32m     91\u001b[0m     )\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\phd\\lib\\site-packages\\polars\\_utils\\deprecation.py:92\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m     89\u001b[0m     _rename_keyword_argument(\n\u001b[0;32m     90\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[0;32m     91\u001b[0m     )\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\phd\\lib\\site-packages\\polars\\io\\csv\\functions.py:503\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(source, has_header, columns, new_columns, separator, comment_prefix, quote_char, skip_rows, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, use_pyarrow, storage_options, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m prepare_file_arg(\n\u001b[0;32m    497\u001b[0m         source,\n\u001b[0;32m    498\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    501\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    502\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[1;32m--> 503\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43m_read_csv_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhas_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprojection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseparator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcomment_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquote_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnull_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnull_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtry_parse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtry_parse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf8-lossy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrechunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrechunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrow_index_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_index_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrow_index_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_index_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m            \u001b[49m\u001b[43meol_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meol_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m            \u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m            \u001b[49m\u001b[43mglob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_columns:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _update_columns(df, new_columns)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\phd\\lib\\site-packages\\polars\\io\\csv\\functions.py:649\u001b[0m, in \u001b[0;36m_read_csv_impl\u001b[1;34m(source, has_header, columns, separator, comment_prefix, quote_char, skip_rows, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    647\u001b[0m projection, columns \u001b[38;5;241m=\u001b[39m parse_columns_arg(columns)\n\u001b[1;32m--> 649\u001b[0m pydf \u001b[38;5;241m=\u001b[39m \u001b[43mPyDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprojection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrechunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquote_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessed_null_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_parse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_row_index_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_index_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_index_offset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43meol_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meol_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(pydf)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dane_1472 =  pl.read_csv('C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol2\\\\1472_all.csv' , n_rows = 5000000 , ignore_errors=True ) #12sek\n",
    "\n",
    "dane_2004 =  pl.read_csv('C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\2004_data.csv' , n_rows = 5000000 , ignore_errors=True ) #11sek\n",
    "dane_2004 = dane_2004.drop(dane_2004.columns[0]) #jeśli jest 100 kolumn\n",
    "\n",
    "dane_6139 =  pl.read_csv('C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\6139_data.csv' , n_rows = 5000000 , ignore_errors=True ) #8sek\n",
    "dane_6139 = dane_6139.drop(dane_6139.columns[0]) #jeśli jest 100 kolumn\n",
    "\n",
    "dane_8281 =  pl.read_csv('C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\8281_data.csv' , n_rows = 5000000 , ignore_errors=True ) #8sek\n",
    "dane_8281 = dane_8281.drop(dane_8281.columns[0]) #jeśli jest 100 kolumn\n",
    "\n",
    "dane1 = [dane_1472, dane_2004, dane_6139, dane_8281]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "probka =  pl.read_csv('C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol2\\\\1472_all.csv' , n_rows = 50 , ignore_errors=True ) #12sek\n",
    "kolumny = probka.columns\n",
    "reference_schema = probka.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dane_data(dane, mr ):\n",
    "    # Step 1: Perform a left join on the 'mr' column\n",
    "    dane = dane.join(mr, on='mr', how='left')\n",
    "    start_col='pcm_LOGenergy_sma' \n",
    "    end_col='pcm_fftMag_mfcc_12_'\n",
    "    # Step 2: Dynamically select columns between start_col and end_col, plus additional specified columns\n",
    "    all_columns = dane.columns\n",
    "    start_idx = all_columns.index(start_col)\n",
    "    end_idx = all_columns.index(end_col)\n",
    "    \n",
    "    # Select specific columns along with the dynamically sliced columns\n",
    "    dane = dane.select(\n",
    "        ['mr', 'patient_id', 'chunk_number', 'frame_nr', 'create_date', 'date', 'visit_date', 'time_point',  'label', 'chunks_count', 'euthymia', 'depression', 'mania', 'mixed','confidence_gauss', 'confidence_linear' ,'confidence_constant' ] \n",
    "        + all_columns[start_idx:end_idx + 1]\n",
    "    )\n",
    "    \n",
    "    # Step 3: Filter rows where 'time_point' is in the specified range\n",
    "    dane = dane.filter(pl.col('time_point').is_in(['-7', '-6', '-5', '-4', '-3', '-2', '-1', '0', '1', '2']))\n",
    "    \n",
    "    return dane\n",
    " \n",
    "# Funkcja do rzutowania kolumn na typy zgodne ze schematem referencyjnym\n",
    "def cast_to_reference_schema(df, reference_schema):\n",
    "    return df.with_columns([\n",
    "        pl.col(col_name).cast(reference_schema[col_name]) \n",
    "        for col_name in df.columns if col_name in reference_schema  # Rzutowanie tylko istniejących kolumn\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Utwórz próbkę danych, aby ustalić `reference_schema`\n",
    "probka = pl.read_csv('C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol2\\\\1472_all.csv', n_rows=50, ignore_errors=True)\n",
    "kolumny = probka.columns\n",
    "reference_schema = probka.schema\n",
    "\n",
    "\n",
    "mr = mr.with_columns([pl.col(\"mr\").cast(pl.Int64)])\n",
    "mr = mr.lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    # Pliki z katalogu vol1\n",
    "    # 'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\0681_data.csv',\n",
    "    # 'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\1153_data.csv',\n",
    "    # 'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\2500_data.csv',\n",
    "    # 'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\4614_data.csv',\n",
    "    # 'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\4953_data.csv',\n",
    "    'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\5656_data.csv',\n",
    "    'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\6139_data.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\6241_data.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\6601_data.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\6754_data.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\7297_data.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\7379_data.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\8193_data.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\8281_data.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\8779_data.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\8866_data.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\9813_data.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol1\\\\9829_data.csv',\n",
    "    \n",
    "    \n",
    "    # Pliki z katalogu vol2\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol2\\\\1472_all.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol2\\\\1981_all.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol2\\\\2582_all.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol2\\\\6701_all.csv',\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\vol2\\\\8560_all.csv',\n",
    "\n",
    "    # Pliki spoza katalogów vol1 i vol2\n",
    "    #'C:\\\\Users\\\\user\\\\Documents\\\\danonki\\\\2004_data.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przetwarzanie w grupach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dane_data(dane, mr ):\n",
    "    # Step 1: Perform a left join on the 'mr' column\n",
    "    dane = dane.join(mr, on='mr', how='left')\n",
    "    start_col='pcm_LOGenergy_sma' \n",
    "    end_col='pcm_fftMag_mfcc_12_'\n",
    "    # Step 2: Dynamically select columns between start_col and end_col, plus additional specified columns\n",
    "    all_columns = dane.columns\n",
    "    start_idx = all_columns.index(start_col)\n",
    "    end_idx = all_columns.index(end_col)\n",
    "    \n",
    "    # Select specific columns along with the dynamically sliced columns\n",
    "    dane = dane.select(\n",
    "        ['mr', 'patient_id', 'chunk_number', 'frame_nr', 'create_date', 'date', 'visit_date', 'time_point', \n",
    "         'confidence', 'label', 'chunks_count', 'euthymia', 'depression', 'mania', 'mixed'] \n",
    "        + all_columns[start_idx:end_idx + 1]\n",
    "    )\n",
    "    \n",
    "    # Step 3: Filter rows where 'time_point' is in the specified range\n",
    "    dane = dane.filter(pl.col('time_point').is_in(['-7', '-6', '-5', '-4', '-3', '-2', '-1', '0', '1', '2']))\n",
    "    \n",
    "    return dane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przetwarzanie pliku 1/2: C:\\Users\\user\\Documents\\danonki\\vol1\\5656_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14828\\2621394214.py:13: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  for col_name in df.columns if col_name in reference_schema\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14828\\2651908419.py:7: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  all_columns = dane.columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zapisano plik: ./danonki/5656_data_confidence.csv\n",
      "Przetwarzanie pliku 2/2: C:\\Users\\user\\Documents\\danonki\\vol1\\6139_data.csv\n",
      "Zapisano plik: ./danonki/6139_data_confidence.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Funkcja do rzutowania kolumn zgodnie z `reference_schema`\n",
    "def cast_to_reference_schema(df, reference_schema):\n",
    "    return df.with_columns([\n",
    "        pl.col(col_name).cast(reference_schema[col_name]) \n",
    "        for col_name in df.columns if col_name in reference_schema\n",
    "    ])\n",
    "\n",
    "def cast_to_reference_schema_special(df, reference_schema):\n",
    "    return df.with_columns([\n",
    "        # Jeśli docelowy typ to Int64, wykonaj najpierw cast na Float64, a potem na Int64\n",
    "        pl.col(col_name).cast(pl.Float64).cast(pl.Int64) if reference_schema[col_name] == pl.Int64 \n",
    "        else pl.col(col_name).cast(reference_schema[col_name])  # Dla pozostałych kolumn wykonaj zwykłe rzutowanie\n",
    "        for col_name in df.columns if col_name in reference_schema\n",
    "    ])\n",
    "\n",
    "# Przetwarzanie plików\n",
    "for i, path in enumerate(file_paths):\n",
    "    print(f\"Przetwarzanie pliku {i + 1}/{len(file_paths)}: {path}\")\n",
    "\n",
    "    # Lazy load ramki z rzutowaniem\n",
    "    dane_lazy = (\n",
    "        pl.scan_csv(path, ignore_errors=True)\n",
    "        .select(kolumny)\n",
    "        .with_columns([\n",
    "            pl.col(\"mr\").cast(pl.Int64),  # Upewnij się, że `mr` jest spójny\n",
    "            pl.col(\"chunk_number\").cast(pl.Float64).cast(pl.Int64) ,\n",
    "            #pl.col('frame_nr').cast(pl.Float64).cast(pl.Int64) \n",
    "        ])\n",
    "        .filter(pl.col('chunk_number') == 0)\n",
    "    )\n",
    "\n",
    "\n",
    "    # Rzutowanie kolumn zgodnie z `reference_schema` - zgodnie z kodem z zapytania\n",
    "    if os.path.basename(path) in [\"6139_data.csv\", \"5656_data.csv\"]:  # Warunek na pliki 6139 i 5656\n",
    "        dane_lazy = cast_to_reference_schema_special(dane_lazy, reference_schema)\n",
    "\n",
    "    # Przetwarzanie danych\n",
    "    data_lazy = process_dane_data(dane=dane_lazy, mr=mr)\n",
    "    \n",
    "    # Zapis wyników do pliku\n",
    "    output_path = f'./danonki/{os.path.splitext(os.path.basename(path))[0]}_confidence.csv'\n",
    "    \n",
    "    try:\n",
    "        data_lazy.sink_csv(output_path)\n",
    "        print(f'Zapisano plik: {output_path}')\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd podczas zapisu pliku {output_path}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
